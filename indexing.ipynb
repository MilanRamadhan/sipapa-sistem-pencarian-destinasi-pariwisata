{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb4bbab",
   "metadata": {},
   "source": [
    "# Indexing Dokumen Pariwisata (DetikTravel & KompasTravel)\n",
    "\n",
    "Notebook ini melakukan tahap **indexing** untuk tugas Penelusuran Informasi:\n",
    "\n",
    "1. Load hasil preprocessing (`corpus_clean.csv`)\n",
    "2. Membuat `doc_id` dan menghitung panjang dokumen\n",
    "3. Membuat **inverted index** (term → {doc_id: tf})\n",
    "4. Menghitung statistik dasar: jumlah dokumen, ukuran vocabulary, df, idf\n",
    "5. Menyimpan metadata dokumen & inverted index agar bisa dipakai di tahap TF-IDF / BM25 / pencarian query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3073691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS_PATH: data/corpus_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Sesuaikan dengan lokasi file kamu\n",
    "# Kalau preprocessing.ipynb tadi menyimpan ke \"data/corpus_clean.csv\", pakai ini:\n",
    "CORPUS_PATH = \"data/corpus_clean.csv\"\n",
    "\n",
    "# Kalau file sekarang masih sejajar notebook:\n",
    "# CORPUS_PATH = \"corpus_clean.csv\"\n",
    "\n",
    "DOC_META_PATH = \"data/doc_meta.csv\"\n",
    "INVERTED_INDEX_PATH = \"data/inverted_index.json\"\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "print(\"CORPUS_PATH:\", CORPUS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25528074",
   "metadata": {},
   "source": [
    "## 1. Load Corpus Bersih (corpus_clean.csv)\n",
    "\n",
    "Kita baca hasil preprocessing yang berisi kolom:\n",
    "\n",
    "- `url`\n",
    "- `title`\n",
    "- `word_count_raw`\n",
    "- `word_count_clean`\n",
    "- `content_raw`\n",
    "- `content_clean`\n",
    "\n",
    "Indexing akan menggunakan **content_clean** sebagai teks yang sudah diprepro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "271366e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dokumen: 4700\n",
      "Index(['url', 'title', 'word_count_raw', 'word_count_clean', 'content_raw',\n",
      "       'content_clean'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>word_count_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://travel.kompas.com/read/2025/11/11/1900...</td>\n",
       "      <td>Unik! Kamar Hotel Bertema Kereta Api di Jepang...</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://travel.kompas.com/read/2025/11/11/1925...</td>\n",
       "      <td>4 Rekomendasi Wisata di Banyuwangi, Cocok untu...</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://travel.kompas.com/read/2025/05/03/1333...</td>\n",
       "      <td>Itinerary Seharian di Bromo Jawa Timur, dari S...</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://travel.kompas.com/read/2025/11/11/1900...   \n",
       "1  https://travel.kompas.com/read/2025/11/11/1925...   \n",
       "2  https://travel.kompas.com/read/2025/05/03/1333...   \n",
       "\n",
       "                                               title  word_count_clean  \n",
       "0  Unik! Kamar Hotel Bertema Kereta Api di Jepang...               581  \n",
       "1  4 Rekomendasi Wisata di Banyuwangi, Cocok untu...               356  \n",
       "2  Itinerary Seharian di Bromo Jawa Timur, dari S...               535  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CORPUS_PATH)\n",
    "\n",
    "print(\"Jumlah dokumen:\", len(df))\n",
    "print(df.columns)\n",
    "\n",
    "# Tampilkan 3 dokumen teratas untuk memastikan format sudah sesuai\n",
    "df[[\"url\", \"title\", \"word_count_clean\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab59d6",
   "metadata": {},
   "source": [
    "## 2. Tambah `doc_id`, tokenisasi, dan panjang dokumen\n",
    "\n",
    "- `doc_id` akan menjadi ID integer untuk setiap dokumen (0, 1, 2, ...).\n",
    "- Token diambil dari `content_clean` yang sudah diproses.\n",
    "- `doc_len` = jumlah token per dokumen (dipakai untuk statistik & BM25 nanti).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a09028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah dokumen: 4700\n",
      "   doc_id  doc_len\n",
      "0       0      581\n",
      "1       1      356\n",
      "2       2      535\n",
      "3       3      486\n",
      "4       4      375\n",
      "count    4700.000000\n",
      "mean      401.006809\n",
      "std       154.067986\n",
      "min        64.000000\n",
      "25%       309.000000\n",
      "50%       381.000000\n",
      "75%       453.000000\n",
      "max      2247.000000\n",
      "Name: doc_len, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tambahkan kolom doc_id\n",
    "df[\"doc_id\"] = df.index.astype(int)\n",
    "\n",
    "# Fungsi tokenisasi sederhana (content_clean sudah lower + bersih)\n",
    "def tokenize(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    return [t for t in str(text).split() if t]\n",
    "\n",
    "df[\"tokens\"] = df[\"content_clean\"].apply(tokenize)\n",
    "df[\"doc_len\"] = df[\"tokens\"].apply(len)\n",
    "\n",
    "print(\"Jumlah dokumen:\", len(df))\n",
    "print(df[[\"doc_id\", \"doc_len\"]].head())\n",
    "print(df[\"doc_len\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2cd23",
   "metadata": {},
   "source": [
    "## 3. Membangun Inverted Index\n",
    "\n",
    "Struktur inverted index:\n",
    "\n",
    "  - `inverted_index` : `dict[str, dict[int, int]]`  \n",
    "  - key   : term (kata)\n",
    "  - value : dictionary `{doc_id: tf}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b264490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah term unik (vocabulary size): 37662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inverted_index = defaultdict(dict)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    doc_id = int(row[\"doc_id\"])\n",
    "    tokens = row[\"tokens\"]\n",
    "    \n",
    "    # Hitung term frequency di 1 dokumen\n",
    "    term_counts = defaultdict(int)\n",
    "    for tok in tokens:\n",
    "        term_counts[tok] += 1\n",
    "    \n",
    "    # Masukkan ke inverted index\n",
    "    for term, tf in term_counts.items():\n",
    "        inverted_index[term][doc_id] = tf\n",
    "\n",
    "vocab_size = len(inverted_index)\n",
    "print(\"Jumlah term unik (vocabulary size):\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f2a28",
   "metadata": {},
   "source": [
    "## 4. Hitung Document Frequency (df) dan Inverse Document Frequency (idf)\n",
    "\n",
    "- `N`  = total dokumen\n",
    "- `df` = jumlah dokumen yang mengandung term tersebut\n",
    "- `idf` (smoothed) kita pakai rumus:\n",
    "\n",
    "\\[\n",
    "idf(t) = \\log\\left(\\frac{N + 1}{df(t) + 1}\\right) + 1\n",
    "\\]\n",
    "\n",
    "Rumus ini sering dipakai sebagai varian smoothed IDF (menghindari pembagian 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a590a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dokumen (N): 4700\n",
      "Contoh 5 term pertama (term, df, idf):\n",
      "- 'unik': df=581, idf=3.0891\n",
      "- 'kamar': df=373, idf=3.5313\n",
      "- 'hotel': df=872, idf=2.6836\n",
      "- 'tema': df=224, idf=4.0394\n",
      "- 'kereta': df=725, idf=2.8680\n"
     ]
    }
   ],
   "source": [
    "N = len(df)\n",
    "\n",
    "df_term = {term: len(postings) for term, postings in inverted_index.items()}\n",
    "idf = {term: math.log((N + 1) / (df_t + 1)) + 1 for term, df_t in df_term.items()}\n",
    "\n",
    "print(\"Total dokumen (N):\", N)\n",
    "print(\"Contoh 5 term pertama (term, df, idf):\")\n",
    "for i, (term, df_t) in enumerate(df_term.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"- {term!r}: df={df_t}, idf={idf[term]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45cec5",
   "metadata": {},
   "source": [
    "## 5. Simpan Metadata Dokumen & Inverted Index\n",
    "\n",
    "Untuk memudahkan pemakaian di notebook lain (misalnya: TF-IDF, BM25, search UI), kita simpan:\n",
    "\n",
    "1. **Metadata dokumen**:\n",
    "   - `doc_id`\n",
    "   - `url`\n",
    "   - `title`\n",
    "   - `doc_len`\n",
    "\n",
    "2. **Inverted index** ke file JSON:\n",
    "   - Format: `term -> list of {\"doc_id\": int, \"tf\": int}`  \n",
    "     (supaya aman untuk di-JSON-kan, karena key dictionary tidak boleh integer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ebfcdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc metadata disimpan ke: data/doc_meta.csv\n",
      "   doc_id                                                url  \\\n",
      "0       0  https://travel.kompas.com/read/2025/11/11/1900...   \n",
      "1       1  https://travel.kompas.com/read/2025/11/11/1925...   \n",
      "2       2  https://travel.kompas.com/read/2025/05/03/1333...   \n",
      "\n",
      "                                               title  doc_len  \n",
      "0  Unik! Kamar Hotel Bertema Kereta Api di Jepang...      581  \n",
      "1  4 Rekomendasi Wisata di Banyuwangi, Cocok untu...      356  \n",
      "2  Itinerary Seharian di Bromo Jawa Timur, dari S...      535  \n",
      "Inverted index disimpan ke: data/inverted_index.json\n",
      "Ukuran vocabulary: 37662\n",
      "Inverted index disimpan ke: data/inverted_index.json\n",
      "Ukuran vocabulary: 37662\n"
     ]
    }
   ],
   "source": [
    "# 1) Simpan metadata dokumen\n",
    "doc_meta = df[[\"doc_id\", \"url\", \"title\", \"doc_len\"]].copy()\n",
    "doc_meta.to_csv(DOC_META_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Doc metadata disimpan ke:\", DOC_META_PATH)\n",
    "print(doc_meta.head(3))\n",
    "\n",
    "# 2) Siapkan inverted_index dalam format serializable\n",
    "serializable_index = {}\n",
    "for term, postings in inverted_index.items():\n",
    "    serializable_index[term] = [\n",
    "        {\"doc_id\": int(doc_id), \"tf\": int(tf)}\n",
    "        for doc_id, tf in postings.items()\n",
    "    ]\n",
    "\n",
    "with open(INVERTED_INDEX_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_index, f, ensure_ascii=False)\n",
    "\n",
    "print(\"Inverted index disimpan ke:\", INVERTED_INDEX_PATH)\n",
    "print(\"Ukuran vocabulary:\", len(serializable_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba55ab35",
   "metadata": {},
   "source": [
    "## 6. Utility: Cek Posting List untuk Satu Term\n",
    "\n",
    "Fungsi kecil untuk mengecek apakah indexing sudah masuk akal:\n",
    "\n",
    "- Input: sebuah kata (misalnya `\"pantai\"`)\n",
    "- Output: daftar beberapa dokumen yang mengandung kata itu, beserta `tf` dan judul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fa79817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term 'pantai' muncul di 893 dokumen.\n",
      "- doc_id=2776, tf=46, title=18 Wisata Pantai Gunungkidul yang Paling Terkenal, Cocok untuk Liburan Sekolah...\n",
      "- doc_id=4619, tf=46, title=18 Wisata Pantai Gunungkidul yang Paling Terkenal, Cocok untuk Liburan Sekolah...\n",
      "- doc_id=1866, tf=39, title=15 Tempat Wisata Bali, Cocok untuk Libur Panjang...\n",
      "- doc_id=3808, tf=39, title=15 Tempat Wisata Bali, Cocok untuk Libur Panjang...\n",
      "- doc_id=1858, tf=36, title=10 Tempat Wisata Pantai Tersembunyi di Bali, Indah dan Sepi...\n"
     ]
    }
   ],
   "source": [
    "def lihat_posting(term, top_n=10):\n",
    "    term = term.lower().strip()\n",
    "    if term not in inverted_index:\n",
    "        print(f\"Term {term!r} tidak ditemukan di index.\")\n",
    "        return\n",
    "    \n",
    "    postings = inverted_index[term]\n",
    "    print(f\"Term {term!r} muncul di {len(postings)} dokumen.\")\n",
    "    \n",
    "    # Urutkan berdasarkan tf tertinggi\n",
    "    sorted_postings = sorted(postings.items(), key=lambda x: -x[1])[:top_n]\n",
    "    \n",
    "    for doc_id, tf in sorted_postings:\n",
    "        row = df.loc[df[\"doc_id\"] == doc_id].iloc[0]\n",
    "        title = str(row[\"title\"])\n",
    "        print(f\"- doc_id={doc_id}, tf={tf}, title={title[:80]}...\")\n",
    "\n",
    "# Contoh pemakaian:\n",
    "lihat_posting(\"pantai\", top_n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08385f6e",
   "metadata": {},
   "source": [
    "## 7. Ringkasan\n",
    "\n",
    "Pada tahap indexing ini kita sudah:\n",
    "\n",
    "- ✅ Menggunakan `corpus_clean.csv` hasil preprocessing\n",
    "- ✅ Menambahkan `doc_id`, token, dan panjang dokumen\n",
    "- ✅ Membangun **inverted index**: term → {doc_id: tf}\n",
    "- ✅ Menghitung df dan idf untuk setiap term\n",
    "- ✅ Menyimpan:\n",
    "  - `data/doc_meta.csv`\n",
    "  - `data/inverted_index.json`\n",
    "\n",
    "Tahap berikutnya dalam tugas IR:\n",
    "\n",
    "1. Menggunakan index + idf untuk membangun model **TF-IDF** dan **BM25**\n",
    "2. Membuat fungsi pencarian (input query → daftar dokumen ter-relevan)\n",
    "3. Melakukan evaluasi (Precision, Recall, F1, MAP) untuk beberapa query uji.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
